{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75656e5c-2d7e-468f-9fd3-78ccb9c2b501",
   "metadata": {},
   "source": [
    "# 11 - ANOVA de um fator para amostras independentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22959209-89cd-46c1-b02c-7bfa3729ffde",
   "metadata": {},
   "source": [
    "Este material foi traduzido e adaptado de {cite}`carlson2017introduction`.\n",
    "\n",
    "OBJETIVOS DE APRENDIZADO\n",
    "\n",
    "Depois de ler este capítulo, você será capaz de fazer o seguinte:\n",
    "\n",
    "- Identificar quando usar uma ANOVA de amostras independentes;\n",
    "- Explicar a lógica da razão F para ANOVA; \n",
    "- Explicar como o erro de medição, as diferenças individuais e os efeitos do tratamento influenciam o numerador e o denominador da razão F;\n",
    "- Escrever hipóteses nulas e de pesquisa usando símbolos e palavras;\n",
    "- Preencha uma tabela de resumo da ANOVA calculando os graus de liberdade, SQs, QMs e razão F;\n",
    "- Defina uma região crítica e determine se você deve rejeitar ou não rejeitar a hipótese nula;\n",
    "- Calcular tamanhos de efeito e descrevê-los;\n",
    "- Explicar quando e por que os testes post hoc são necessários;\n",
    "- Resumir os resultados de uma ANOVA de amostras independentes;\n",
    "- Usar software para calcular uma ANOVA de amostras independentes, incluindo testes post hoc;\n",
    "- Interpretar a saída do software para uma ANOVA de amostras independentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d72a52-30be-411c-bb78-abda461a8c5d",
   "metadata": {},
   "source": [
    "## ANOVA de amostras independentes\n",
    "\n",
    "O teste t de amostras independentes e o teste t de amostras relacionadas comparam duas médias amostrais para determinar se seu desvio é maior do que seria esperado pelo erro amostral. Ambos os testes t compartilham uma limitação importante, pois só podem comparar duas médias amostrais por vez. Uma ANOVA é substancialmente mais flexível, pois pode comparar duas ou mais médias amostrais ao mesmo tempo para determinar se o desvio entre qualquer par de médias amostrais é maior do que seria esperado pelo erro amostral. Portanto, uma única ANOVA, também conhecida como ANOVA unidirecional ou ANOVA de fator único, pode comparar dois tratamentos (por exemplo, Tratamento A e Tratamento B) entre si, bem como comparar cada um desses tratamentos com uma condição de controle (por exemplo, placebo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b7a17-e25d-4fbc-ad7c-2108996e7a51",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "from jupyterquiz import display_quiz\n",
    "#display_quiz(\"questions.json\", preserve_responses = True)\n",
    "display_quiz(\"question1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40300e1a-dca7-424b-aa8a-9300b6921a4c",
   "metadata": {},
   "source": [
    "## Outros nomes\n",
    "\n",
    "ANOVA é uma abreviatura para Análise de Variância. Uma ANOVA independente, assim como um teste t independente , é usada quando há pessoas diferentes em cada condição do projeto. Por exemplo, se houvesse três tratamentos diferentes que você desejasse comparar em um desenho de amostras independentes, algumas pessoas receberiam o Tratamento A, outras o Tratamento B e o restante o Tratamento C. Este tipo de desenho também é conhecido como desenho entre sujeitos ou um projeto de medidas independentes. Uma ANOVA de amostras relacionadas, assim como um teste t de amostras relacionadas , é usada quando as médias amostrais são geradas pela mesma amostra ou por amostras correspondentes. ANOVAs de amostras independentes e ANOVAs de amostras relacionadas que envolvem apenas uma variável categórica (por exemplo, uma variável independente, VI) são frequentemente chamadas de ANOVAs de um fator. Neste livro, discutiremos apenas ANOVAs de amostras independentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674d524-48e5-45ae-85f6-74e188af1533",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca208d85-73d5-4390-822c-a7ff58aa77e6",
   "metadata": {},
   "source": [
    "## Lógica da ANOVA\n",
    "\n",
    "Todos os testes de significância que você aprendeu até agora (isto é, z para uma média amostral, teste t para amostra única, teste t para amostras independentes e o teste t para amostras relacionadas) compartilham uma lógica comum. Ou seja, para todos eles, você calculou a diferença observada entre duas médias e depois dividiu essa diferença pela diferença que seria esperada devido ao erro amostral. A lógica do teste ANOVA é diferente. Como provavelmente fica evidente pelo nome, uma análise de variância analisa a variância das observações. Especificamente, uma ANOVA analisa a variância das observação entre e dentro das condições da VI, numa tentativa de determinar se as diferentes condições de tratamento afetam os valores de forma diferente. Por exemplo, você poderia usar uma ANOVA para determinar se três condições de tratamento diferentes levam a diferentes valores de depressão. Para compreender a lógica das ANOVAs, você deve entender que três coisas afetam a variância das observações:\n",
    "\n",
    "1. Erro de medição: Sempre haverá variação nas observações entre as unidades amostrais porque as variáveis não podem ser medidas perfeitamente.\n",
    "\n",
    "2. Diferenças individuais: Sempre haverá variação nas observações entre as unidades amostrais porque as unidades são naturalmente diferentes entre si.\n",
    "\n",
    "3. Efeito do tratamento: Pode haver variação nas observações entre os grupos porque estes experimentaram diferentes condições (VI) ou tratamentos.\n",
    "\n",
    "As duas primeiras fontes de variância nas observações, erro de medição e diferenças individuais, estarão sempre presentes. Essas duas fontes de variação são frequentemente chamadas coletivamente de variação de erro porque ambos são componentes do erro amostral. A terceira fonte de variação é realmente o que interessa aos pesquisadores. Os pesquisadores usam a ANOVA para estimar a quantidade de variação das observações criada pelas diferentes condições de tratamento (VI). Ao realizar as atividades deste capítulo, você poderá entender isso melhor. Por enquanto, você tem informações suficientes para entender a lógica da ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b6f77-98ea-4f83-9a3f-127389f4b864",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3622866-ebaf-409d-ac55-23e172852c44",
   "metadata": {},
   "source": [
    "A ANOVA analisa as quantidades relativas dessas três fontes de variabilidade das observações – a saber, (1) efeitos de tratamento, (2) diferenças individuais e (3) erro de medição – para produzir uma estatística F. A fórmula conceitual da ANOVA é uma razão entre a variabilidade entre as condições de tratamento e a variabilidade dentro das condições de tratamento. Duas representações da fórmula conceitual para uma ANOVA independente são mostradas a seguir:\n",
    " \n",
    "$F = \\frac{Variabilidade\\quad entre\\quad condições\\quad de\\quad tratamento}{Variabilidade\\quad dentro\\quad das\\quad condições\\quad de\\quad tratamento}$\n",
    " \n",
    "$F = \\frac{Efeito\\quad do\\quad tratamento\\quad \\&\\quad diferenças\\quad individuais\\quad \\&\\quad erro\\quad de\\quad medição}{Diferenças\\quad individuais\\quad \\&\\quad Erro\\quad de\\quad medição}$\n",
    "\n",
    "O numerador da razão F é a variabilidade nas observações que existe entre os diferentes grupos de tratamento (ou seja, condições da VI), que é chamada de variabilidade entre grupos ou variabilidade entre tratamentos. Por exemplo, se uma condição tivesse valores observados altos e outra condição tivesse valores observados baixos, haveria muita variabilidade entre grupos. No entanto, se todas as condições tivessem valores semelhantes, haveria pouca variabilidade entre grupos. Existem três fontes possíveis para a variabilidade entre tratamentos. É possível que os diferentes tratamentos criem variabilidade entre grupos porque um tratamento é mais eficaz que outro (ou seja, os tratamentos afectam a variável dependente de forma diferente). Esta é a variabilidade na qual os investigadores estão mais interessados. No entanto, alguma da variabilidade entre grupos é sempre causada por diferenças individuais e erros de medição. Assim, o numerador da razão F, a variabilidade entre grupos, consiste em efeitos de tratamento, efeitos de diferenças individuais e erro de medição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2fbbd-a2b8-4c6c-8594-c7349050706f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a434c-fcce-4010-a9ea-f37462f64317",
   "metadata": {},
   "source": [
    "O denominador da razão F é a variabilidade nas observações que existe dentro dos grupos de tratamento (isto é, condições da VI), que é chamada de variabilidade dentro do grupo. Existem duas fontes possíveis para a variabilidade intratratamento: (1) diferenças individuais e (2) erro de medição. É importante notar que as diferenças nas observações dentro de cada condição de tratamento não são causadas por diferenças na eficácia do tratamento porque todas as pessoas dentro de um determinado grupo experimentaram o mesmo tratamento. As únicas fontes de diferenças dentro de uma condição de tratamento são diferenças individuais e erros de medição. O denominador da razão F é frequentemente chamado de termo de erro porque contém apenas a variância criada pelo erro de amostragem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35d22a-0a6b-48f1-878f-fb021501d984",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question5.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5fb7f-bc6b-4261-9386-6e3d2a147e8f",
   "metadata": {},
   "source": [
    "Se você observar as fontes de variação no numerador e no denominador da ANOVA independente, poderá ver que a única diferença é que o numerador inclui efeitos de tratamento e o denominador não. Este fato é crítico para a lógica da ANOVA independente. Imagine uma situação em qual o efeito do tratamento cria variância zero (ou seja, o tratamento não funciona). Se você substituir \"efeito do tratamento\" na fórmula conceitual por \"0\", a equação seria a seguinte:\n",
    "\n",
    "$F = \\frac{0\\quad \\&\\quad diferenças\\quad individuais\\quad \\&\\quad erro}{Diferenças\\quad individuais\\quad \\&\\quad erro}$\n",
    "\n",
    "Com a variância do efeito do tratamento sendo zero, a razão F seria igual a 1 porque o numerador e o denominador seriam o mesmo número. Portanto, se o tratamento não criar variabilidade nas observações, espera-se que a ANOVA produza um valor estatístico F próximo de 1. Por outro lado, se os diferentes tratamentos criarem muita variabilidade nas pontuações, espera-se que o valor F seja substancialmente maior que 1. Um valor ANOVA F não pode ser negativo porque é a razão de duas variâncias, e as variâncias devem ser positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa56ace-36b1-4e1c-8b76-bd061ff0ee67",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question5.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f40bde-1b6d-4bd5-aedf-1a72d8467939",
   "metadata": {},
   "source": [
    "## Um exemplo de problema para ANOVA\n",
    "\n",
    "Você usa uma ANOVA de amostras independentes para comparar as médias de dois ou mais grupos/amostras contendo unidades amostrais diferentes. Por exemplo, suponha que você queira comparar a terapia cognitivo-comportamental (TCC) e a terapia psicodinâmica (TPD) como tratamentos para a depressão. Você identifica uma amostra de pessoas com depressão grave e as divide aleatoriamente em três grupos diferentes. Um grupo é submetido à TCC por 6 meses, um segundo grupo é submetido à TPD por 6 meses e um terceiro grupo funciona como grupo controle e não recebe tratamento (NT). Após 6 meses, você avalia os níveis de depressão usando o Inventário de Depressão de Beck (BDI; os valores variam de 0 a 63), com pontuações mais altas indicando maior depressão. Os valores de depressão encontrados para cada grupo estão listados na Tabela 11.1. Neste estudo, a VI é o tipo de tratamento (TCC, TPD ou TN) e a VD (variável dependente) é o valor de depressão de cada pessoa na escala BDI.\n",
    "\n",
    "_Tabela 11.1 - Valores de depressão após três tipos diferentes de tratamento_\n",
    "\n",
    " Grupo 1 | Grupo 2 | Grupo 3\n",
    " -- | -- | --\n",
    "  **Terapia cognitiva comportamental** | **Terapia Psicodinâmica** | **Controle - sem de tratamento**\n",
    " 5 | 16 | 14\n",
    " 9 | 17 | 19\n",
    " 11 | 18 | 16\n",
    " 6 | 13 | 9\n",
    " 2 | 10 | 15\n",
    " 15 | 19 | 25\n",
    " $\\bar{x}_1 = 8.00$ | $\\bar{x}_2 = 15.50$ | $\\bar{x}_3 = 16.333$\n",
    " $DP_1 = 4.65$ | $DP_2 = 3.39$ | $DP_3 = 5.35$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb625ab-89b5-40df-85cf-65f417c4d12a",
   "metadata": {},
   "source": [
    "### Etapa 1: examinar variáveis para avaliar suposições estatísticas\n",
    "\n",
    "As suposições estatísticas para testes t independentes e ANOVAs independentes são idênticas. Portanto, você deve considerar quatro suposições. No seu estudo, os valores de depressão dos indivíduos devem ser medidos sem que a medição de um participante influencie o de outro (independência de dados). Sua VD, pontuação de depressão, deve ser medida como uma variável quantitativa, e seu VI deve identificar como os três tratamentos terapêuticos são diferentes (medição apropriada de variáveis para ANOVA independente). A distribuição das médias amostrais para cada uma de suas condições deve ter uma forma normal (normalidade). Como foi o caso de alguns exemplos anteriores, os tamanhos amostrais neste estudo (ns = 6) são demasiado pequenos para se ter certeza de que as distribuições das médias amostrais terão uma forma normal, a menos que as populações originais tenham uma forma normal. Você deve tentar obter tamanhos de amostra próximos a 30 participantes por condição (ou seja, perto de 90 participantes no total neste caso). Mas, para fins didáticos, esses tamanhos de amostra menores funcionarão bem. Sua quarta suposição é a homogeneidade de variância. Para ANOVAs, retorne à regra do duplo desvio padrão; se qualquer uma de suas condições tiver um desvio padrão o dobro de outra, a suposição de homogeneidade de variância pode ser violada. Embora existam maneiras de testar variâncias iguais na ANOVA (ver Field, 2013), as ANOVAs são geralmente bastante robustas a violações desta suposição, desde que os tamanhos das amostras sejam aproximadamente iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541365e-987f-4c97-a393-a1df83f68ecc",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question6.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d99b9-8d0d-4c1a-a8f6-106b84c15d44",
   "metadata": {},
   "source": [
    "### Etapa 2: expor as hipóteses nulas e de pesquisa\n",
    "\n",
    "Sua segunda etapa é estabelecer as hipóteses nula e de pesquisa. A hipótese nula sempre afirma que todas as populações têm os mesmos valores médios da VD. Nesse caso, a hipótese nula afirma que as três populações de pessoas estudadas (isto é, aquelas que recebem TCC, TPD ou TN) têm os mesmos valores médios de depressão; quaisquer diferenças observadas nas amostras são devidas a erros amostrais. Em contraste, a hipótese de investigação afirma que os valores médios da VD das três populações não são iguais.\n",
    "Neste caso, a hipótese de investigação afirma que pelo menos uma dos valores médios de depressão das populações é significativamente diferente de pelo menos uma das outras. Observe que a hipótese de pesquisa não especifica que todas as médias da população são diferentes, apenas que pelo menos uma média da população é diferente de pelo menos uma dos outros. A hipótese da pesquisa diz que um ou mais dos tratamentos funcionam melhor do que um ou mais dos outros. A Tabela 11.2 resume como escrever as hipóteses nula e de pesquisa.\n",
    "\n",
    "Tipo de Hipótese | Simbólico | Vebal | Diferença entre médias amostral e populacional\n",
    "-- | -- | -- | --\n",
    " Hipótese nula | $H_0:\\mu_1=\\mu_2=...=\\mu_K;$ | Médias $\\approx$ para todas populações | Erro amostral\n",
    " Hipótese de pesquisa | $H_a:\\mu_i \\neq \\mu_j.$ | Médias $\\neq$ para pelo menos um par | Um ou mais tratamentos têm efeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedccab-d0a7-4f9d-a52f-177d78f822e8",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question7.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790f793-9618-4ae7-b8de-059ef010affa",
   "metadata": {},
   "source": [
    "### Etapa 3: Definir o valor crítico de F\n",
    "\n",
    "Tal como acontece com os testes t, você usa um valor crítico para determinar se deve rejeitar o nulo, mas precisará de dois valores gl diferentes para encontrar o valor crítico de F. Você precisará de um valor gl baseado no número de participantes e outro valor gl baseado no número de grupos. Se a hipótese nula for verdadeira, o valor F obtido deve estar próximo de 1. Se a hipótese nula for falsa, o valor F obtido deve ser muito maior que 1. Mas a que distância de 1 um valor F deve estar para rejeitar a hipótese nula? Se o valor F for igual ou maior que o valor F crítico, você rejeita a hipótese nula.\n",
    "\n",
    "Especificamente, você precisará dos graus de liberdade entre tratamentos (gl_entre) e dos graus de liberdade dentro dos tratamentos (gl_dentro(error)) para encontrar o valor F crítico. Esses gls são calculados com as seguintes fórmulas, respectivamente:\n",
    "\n",
    "gl_entre = g - 1, entre onde g representa o número de grupos/condições de tratamento, e\n",
    "\n",
    "gl_dentro = N-g , onde N representa o número de valores em estudo inteiro.\n",
    "\n",
    "Neste caso, o gl_entre = 3 - 1 = 2, e o gl_dentro = 18 - 3 = 15. Você usa esses valores gl para encontrar o valor crítico de F no Apêndice C. O Apêndice C contém valores críticos para níveis alfa de 0.05 e 0.01 em duas tabelas separadas. O gl_entre (neste caso, 2) indica a coluna, e o gl_dentro (neste caso, 15) indica a linha para encontrar o valor crítico de F. Conforme ilustrado na Figura 11.1, o valor crítico de F quando os dfs são 2 e 15 e usando um valor alfa de 0.05 é 3.68. Portanto, se o valor F observado fosse maior que 3.68, você rejeita a hipótese nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a70fb20-2184-4ed1-973d-3a6bcd0197d4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e3672_row1_col0, #T_e3672_row1_col1, #T_e3672_row1_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e3672\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e3672_level0_col0\" class=\"col_heading level0 col0\" >1</th>\n",
       "      <th id=\"T_e3672_level0_col1\" class=\"col_heading level0 col1\" >2</th>\n",
       "      <th id=\"T_e3672_level0_col2\" class=\"col_heading level0 col2\" >3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e3672_level0_row0\" class=\"row_heading level0 row0\" >14</th>\n",
       "      <td id=\"T_e3672_row0_col0\" class=\"data row0 col0\" >4.600100</td>\n",
       "      <td id=\"T_e3672_row0_col1\" class=\"data row0 col1\" >4.543100</td>\n",
       "      <td id=\"T_e3672_row0_col2\" class=\"data row0 col2\" >4.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3672_level0_row1\" class=\"row_heading level0 row1\" >15</th>\n",
       "      <td id=\"T_e3672_row1_col0\" class=\"data row1 col0\" >3.738900</td>\n",
       "      <td id=\"T_e3672_row1_col1\" class=\"data row1 col1\" >3.682300</td>\n",
       "      <td id=\"T_e3672_row1_col2\" class=\"data row1 col2\" >3.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3672_level0_row2\" class=\"row_heading level0 row2\" >16</th>\n",
       "      <td id=\"T_e3672_row2_col0\" class=\"data row2 col0\" >3.343900</td>\n",
       "      <td id=\"T_e3672_row2_col1\" class=\"data row2 col1\" >3.287400</td>\n",
       "      <td id=\"T_e3672_row2_col2\" class=\"data row2 col2\" >3.238900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x788efa1c4700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "gl_entre = [1, 2, 3]\n",
    "gl_dentro = [14, 15, 16]\n",
    "\n",
    "a05 = []\n",
    "for i in gl_entre:\n",
    "    tmp = []\n",
    "    for j in gl_dentro:\n",
    "        tmp.append(round(stats.f(i, j).ppf(0.95), 4))\n",
    "    a05.append(tmp)\n",
    "\n",
    "df = pd.DataFrame(a05, columns=gl_entre, index=gl_dentro)\n",
    "\n",
    "color = (df.iloc[:,1] == df.iloc[1,1]).map({True: 'background-color: yellow', False: ''})\n",
    "\n",
    "df.style.apply(lambda s: color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861392e-25d5-4c96-94f7-fab62c0bfcd4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question8.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7a809-59a5-4c9f-a925-58112569e34d",
   "metadata": {},
   "source": [
    "### Etapa 4: Calculando a estatística do teste (ANOVA independente)\n",
    "\n",
    "_4a–4d. Completando a Tabela Resumo da ANOVA_\n",
    "\n",
    "Para calcular a razão F , você precisa calcular dois números: (1) a variância entre as condições de tratamento e (2) a variância dentro das condições de tratamento. Neste livro, até agora, você geralmente calculou o desvio padrão para medir a variabilidade. No entanto, ao fazer uma ANOVA, você calcula a variância como uma medida de variabilidade. Você deve se lembrar que a variância da amostra é o desvio médio quadrático das observações em relação à média e é calculada dividindo a SQ pelo seu gl. Na terminologia ANOVA, a variância é referida como quadrado médio (abreviado como QM). Embora a terminologia seja um pouco diferente, a lógica é a mesma. Para calcular cada QM, você divide cada SQ por seu gl. Esses cálculos são normalmente feitos usando um pacote de _software_ (por exemplo, Google Sheet), e os resultados são frequentemente apresentados em uma tabela fonte ANOVA. Uma tabela de origem ANOVA é um resumo valioso da análise estatística ANOVA porque mostra como o F obtido é criado. A tabela de origem lista as fontes de variação discutidas nas seções anteriores, entre e dentro dos tratamentos, na primeira coluna. Os títulos das colunas indicam as etapas necessárias para calcular um F: SQ, gl, QM e, finalmente, F. A Tabela 11.3 é uma tabela fonte da ANOVA. As fórmulas para gl, SQ, F e $\\nu^2$ são apresentadas porque a melhor maneira de entender as inter-relações entre esses termos é ver como cada valor é gerado. A $SQ_{entre}$ representa a soma da variabilidade criada pelo efeito do tratamento, diferenças individuais e erro de medição. Você calcula o $SQ_{entre}$ calculando a SQ para as médias dos três grupos e depois multiplicando esse valor $SQ_{medias}$ por n (ou seja, o número de unidades amostrais em cada grupo). Nesse caso, as médias dos três grupos são 8.0, 15.5 e 16.3333, respectivamente. Portanto, seu $SQ_{media}$ é a SQ destas três médias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60a7f4-eb0e-4a0a-9f43-f97399b575b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
